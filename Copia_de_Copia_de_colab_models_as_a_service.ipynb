{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aa2machiste/aaz/blob/main/Copia_de_Copia_de_colab_models_as_a_service.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16d9e8e0-b783-4d33-83b4-5d450bf02191",
        "id": "jcJFIHBqWw_u"
      },
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# El token debe ir entre comillas para ser válido\n",
        "auth_token = \"38C7qOpsgGgphXiJk02QkZLk6rD_3wcqGWSeRpqzjgdKHbDRo\"\n",
        "\n",
        "# Configurar el token\n",
        "ngrok.set_auth_token(auth_token)\n",
        "print(\"\\n¡Authtoken configurado! Ahora vuelve a ejecutar la celda de la aplicación Flask para iniciar el servidor.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "¡Authtoken configurado! Ahora vuelve a ejecutar la celda de la aplicación Flask para iniciar el servidor.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWzdSztXWcpg"
      },
      "source": [
        "# Colab AI: List available models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ucchuu5vV3Jp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc6252bc-0c19-4c9a-861d-ad0ff55ae212"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['google/gemini-2.0-flash',\n",
              " 'google/gemini-2.0-flash-lite',\n",
              " 'google/gemini-2.5-flash',\n",
              " 'google/gemini-2.5-flash-lite',\n",
              " 'google/gemini-2.5-pro',\n",
              " 'google/gemini-3-pro-preview',\n",
              " 'google/gemma-3-12b',\n",
              " 'google/gemma-3-1b',\n",
              " 'google/gemma-3-27b',\n",
              " 'google/gemma-3-4b']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from google.colab import ai\n",
        "ai.list_models()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kpZlLU34gCRz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f4ce202-3187-4ebe-8074-3419abc06460"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjfCGEpzDsD9"
      },
      "source": [
        "The model names give you a hint about their capabilities and intended use:\n",
        "\n",
        "Pro: These are the most capable models, ideal for complex reasoning, creative tasks, and detailed analysis.\n",
        "\n",
        "Flash: These models are optimized for high speed and efficiency, making them great for summarization, chat applications, and tasks requiring rapid responses.\n",
        "\n",
        "Gemma: These are lightweight, open-weight models suitable for a variety of text generation tasks and are great for experimentation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oypl6kfOX9Jw"
      },
      "source": [
        "# Colab AI: Choose a different model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHO9VzO9AHZP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7502cb4-7d42-4d12-a838-cb7c392037b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The capital of England is **London**.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from google.colab import ai\n",
        "\n",
        "response = ai.generate_text(\"What is the capital of England\", model_name='google/gemini-2.0-flash-lite')\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpUByA5CYQTa"
      },
      "source": [
        "# Colab AI: Simple batch generation example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0rmsI9zYJ-o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fe1ced1-b6d5-4177-c944-1682b0ab1692"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The capital of France is **Paris**.\n"
          ]
        }
      ],
      "source": [
        "# Only text-to-text input/output is supported\n",
        "from google.colab import ai\n",
        "\n",
        "response = ai.generate_text(\"What is the capital of France?\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvJPCM4cYawP"
      },
      "source": [
        "# Colab AI: Simple streaming example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BNgxiB6--_5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "390d1c49-0d14-4316-dd7e-e6ccb6ce04aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elara bought the house because of its silence. Not an empty silence, but one thick with generations of unspoken stories, like dust motes dancing in sunbeams. It was old, drafty, and smelled faintly of lavender and forgotten paper. Her first task was the attic – a chaotic symphony of trunks, yellowed linens, and furniture draped like sleeping giants.\n",
            "\n",
            "One sweltering afternoon, she pulled back a heavy canvas sheet from what she assumed was a discarded chest. Instead, her fingers met smooth, dark wood. Beneath the dust and cobwebs lay a mandolin case, surprisingly intact. It wasn't ornate, but beautifully crafted, its dark wood worn soft in places, hinting at countless hours in someone's hands.\n",
            "\n",
            "With a click, the latches sprang open. Inside, nestled on faded velvet, was the mandolin. Its strings were loose, spiderwebbed with dust, and one tuning peg was missing. But even in disarray, it held a quiet grace. A faint, sweet scent, like dried rose petals, clung to it.\n",
            "\n",
            "Elara carefully lifted it out. It was lighter than she expected. As her fingers traced the curve of its body, she felt a small protrusion near the sound hole. A tiny, almost invisible catch. She pressed it, and a sliver of wood popped open, revealing a hidden compartment no bigger than her thumb.\n",
            "\n",
            "Inside lay a single, folded piece of paper. It was brittle, the ink faded to sepia, but legible.\n",
            "\n",
            "\"My dearest Elara,\" it read, in elegant, looping script. \"If you find this, know that these notes were born of a love that defied time. May this melody find you, wherever you are.\" Below it, a single, simple stave of music was drawn, just a few notes, stark against the aged paper.\n",
            "\n",
            "A shiver ran down Elara's spine. *Her* name. A coincidence, surely. But the warmth in the words, the yearning in the faded ink, felt impossibly personal.\n",
            "\n",
            "She found an old tuning fork and painstakingly tightened the remaining strings, her fingers fumbling with the unfamiliar instrument. The first plucked notes were tinny, discordant, a protest from the long-dormant wood. But she looked at the little melody on the paper, humming it softly, letting the rhythm seep into her.\n",
            "\n",
            "Then, she tried again. Her fingers, hesitant at first, found the positions. The notes, simple and aching, emerged from the mandolin, not perfectly, but with a haunting clarity. It was a melody of longing, of quiet joy, of love whispered across decades.\n",
            "\n",
            "The attic, which had once felt merely old, now felt alive. The dust motes seemed to dance not just in sunbeams, but to the tune of the mandolin. Elara played the short piece again and again, each time a little more fluidly, each time feeling a deeper connection to the unknown Elara who had loved and been loved, and to the silent hand that had hidden the music away.\n",
            "\n",
            "The house hadn't been silent at all. It had just been waiting for someone to listen. And now, Elara, the new custodian of its stories, began to play."
          ]
        }
      ],
      "source": [
        "from google.colab import ai\n",
        "\n",
        "stream = ai.generate_text(\"Tell me a short story.\", stream=True)\n",
        "for text in stream:\n",
        "  print(text, end='')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBJk0a4rY-n1"
      },
      "source": [
        "# Colab AI: Formatted streaming example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpMmpaVClSBV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dfa8d54-67be-4784-b78b-3688fe146f79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alright, buckle up, because charting the evolution of the Roman Empire is like\n",
            "navigating a sprawling, millennia-old labyrinth. It's a story of humble\n",
            "beginnings, audacious expansion, catastrophic crises, and ultimately, a slow,\n",
            "multi-faceted disintegration. Forget easy chapters; this is more like a tapestry\n",
            "woven with ambition, innovation, brutality, and an enduring legacy that\n",
            "continues to shape our world.\n",
            "\n",
            "We begin not with emperors and legions, but with the *Romulus and Remus* myth, a\n",
            "foundation story as much symbolic as historical. Around the 8th century BCE, a\n",
            "collection of small villages nestled on the Palatine Hill, overlooking the Tiber\n",
            "River, coalesced into what would eventually become Rome. This was the era of the\n",
            "Roman Kingdom, a period shrouded in legend but likely characterized by a\n",
            "succession of kings, possibly influenced by the Etruscans to the north. While we\n",
            "know less about this era than later periods, it was crucial in establishing\n",
            "foundational societal structures, religious practices, and early military\n",
            "traditions. Think of it as the embryonic stage, laying the groundwork for future\n",
            "growth.\n",
            "\n",
            "Then, in 509 BCE, a revolution! The Romans, weary of perceived tyrannical rule,\n",
            "expelled their last king, Tarquinius Superbus, and established the **Roman\n",
            "Republic**. This marked a pivotal shift. No more kings; instead, power was\n",
            "vested in elected officials, namely the Senate and various assemblies. The\n",
            "Senate, comprised of wealthy and influential patricians, initially dominated,\n",
            "but struggles for power between the patricians and the plebeians (the common\n",
            "people) became a constant feature of the Republic. This internal dynamic fueled\n",
            "both political innovation and periods of intense social unrest.\n",
            "\n",
            "The early Republic was characterized by near-constant warfare. Survival wasn't\n",
            "guaranteed. Rome fought against neighboring city-states and tribes for its very\n",
            "existence, slowly but surely expanding its territory and influence throughout\n",
            "Latium. Think of it as Rome flexing its nascent muscles, learning the art of\n",
            "conquest and forging a legendary military machine. The development of the Roman\n",
            "legion, a highly disciplined and adaptable fighting force, was key to their\n",
            "success.\n",
            "\n",
            "As Rome grew, so did its ambitions. The Punic Wars (264-146 BCE), a series of\n",
            "epic conflicts against Carthage, a powerful Phoenician trading empire based in\n",
            "North Africa, were a turning point. These wars, punctuated by legendary figures\n",
            "like Hannibal Barca and his daring trek across the Alps with war elephants,\n",
            "transformed Rome from a regional power into a dominant force in the\n",
            "Mediterranean. Victory in the Punic Wars brought immense wealth, new territories\n",
            "(Sicily, Sardinia, Spain, and eventually North Africa), and a growing sense of\n",
            "Roman exceptionalism.\n",
            "\n",
            "However, this success came at a cost. The influx of wealth and enslaved labor\n",
            "destabilized Roman society. Farmers, unable to compete with large,\n",
            "slave-operated estates (latifundia ), flocked to the cities, creating a landless\n",
            "proletariat ripe for exploitation. The widening gap between rich and poor fueled\n",
            "social unrest and political corruption. Powerful generals, like Marius and\n",
            "Sulla, used their armies to further their own ambitions, leading to bloody civil\n",
            "wars that further undermined the Republic's institutions.\n",
            "\n",
            "The late Republic witnessed the rise and fall of iconic figures like Julius\n",
            "Caesar. Caesar, a brilliant general and politician, conquered Gaul (modern-day\n",
            "France), further expanding Roman territory and gaining immense popularity with\n",
            "his troops and the populace. His ambition and defiance of the Senate,\n",
            "culminating in his famous crossing of the Rubicon River in 49 BCE, plunged Rome\n",
            "into another devastating civil war. Caesar's victory and subsequent assumption\n",
            "of dictatorial powers (dictator perpetuo, dictator for life) effectively\n",
            "signaled the end of the Republic. His assassination in 44 BCE by a group of\n",
            "senators, fearing his ambition, didn't restore the Republic, but instead\n",
            "triggered yet another round of civil war.\n",
            "\n",
            "Out of this chaos emerged Octavian, Caesar's adopted son. After defeating his\n",
            "rivals, including Mark Antony and Cleopatra, Octavian consolidated his power.\n",
            "Recognizing the Republic was beyond saving, he shrewdly avoided the title of\n",
            "king or dictator. Instead, he presented himself as *princeps*, \"first citizen,\"\n",
            "and skillfully manipulated the existing Republican institutions to maintain\n",
            "control. In 27 BCE, the Senate bestowed upon him the title of *Augustus*, and\n",
            "with that, the **Roman Empire** was born.\n",
            "\n",
            "The early Empire, known as the Principate (because Augustus ruled as\n",
            "*princeps*), was a period of relative peace and prosperity known as the *Pax\n",
            "Romana* (\"Roman Peace\"). Augustus and his successors focused on consolidating\n",
            "imperial power, expanding infrastructure (roads, aqueducts, public buildings),\n",
            "and promoting trade. The Empire grew to encompass vast territories stretching\n",
            "from Britannia in the north to Egypt in the south, and from Spain in the west to\n",
            "Mesopotamia in the east. This era saw the flourishing of Roman law, literature,\n",
            "and art.\n",
            "\n",
            "However, even during the Pax Romana, cracks began to appear. The succession to\n",
            "the imperial throne was often fraught with intrigue and violence. The reign of\n",
            "emperors like Caligula and Nero, known for their alleged madness and cruelty,\n",
            "demonstrated the inherent instability of autocratic rule. The Praetorian Guard,\n",
            "the emperor's personal bodyguard, gained immense power and frequently intervened\n",
            "in imperial successions.\n",
            "\n",
            "Over time, the challenges facing the Empire multiplied. Barbarian incursions\n",
            "along the frontiers became more frequent and more threatening. Economic\n",
            "problems, including inflation and debasement of the currency, plagued the\n",
            "economy. Political instability, characterized by short-lived emperors and\n",
            "frequent civil wars, became a chronic problem.\n",
            "\n",
            "In the late 3 rd century CE, Emperor Diocletian attempted to address these\n",
            "challenges through radical reforms. He divided the Empire into two halves – the\n",
            "Western Roman Empire and the Eastern Roman Empire (later known as the Byzantine\n",
            "Empire) – each ruled by an emperor and a subordinate \"Caesar.\" This system,\n",
            "known as the Tetrarchy (\" rule by four\"), was intended to provide more effective\n",
            "governance and defense. However, it ultimately proved unsustainable and led to\n",
            "further internal conflict.\n",
            "\n",
            "Constantine the Great, who succeeded Diocletian after a period of civil war,\n",
            "reunited the Empire and made two key decisions that profoundly shaped its\n",
            "future. First, he legalized Christianity with the Edict of Milan in 313 CE,\n",
            "eventually paving the way for its adoption as the state religion. Second, he\n",
            "moved the capital from Rome to Byzantium, renaming it Constantinople (modern-day\n",
            "Istanbul). This move reflected the shifting center of gravity within the Empire,\n",
            "as the Eastern provinces became increasingly wealthy and strategically important\n",
            ".\n",
            "\n",
            "After Constantine's death, the division of the Empire became permanent. While\n",
            "the Eastern Roman Empire, with its capital at Constantinople, flourished for\n",
            "centuries, the Western Roman Empire continued to decline under the pressure of\n",
            "internal problems and external threats. Wave after wave of barbarian migrations\n",
            "– Goths, Vandals, Franks, and others – swept across the Western provinces,\n",
            "eroding Roman authority and plundering its cities.\n",
            "\n",
            "The final blow came in 476 CE, when the last Roman Emperor of the West, Romulus\n",
            "Augustulus, was deposed by a barbarian general named Odoacer. While technically,\n",
            "the Eastern Roman Emperor continued to claim sovereignty over the West, in\n",
            "reality, the Western Roman Empire had ceased to exist. Its territories were\n",
            "fragmented into various barbarian kingdoms.\n",
            "\n",
            "However, this wasn't the end of the story. The Eastern Roman Empire, or\n",
            "Byzantine Empire, continued to thrive for another thousand years, preserving\n",
            "Roman law, culture, and administrative traditions. Even in the West, the legacy\n",
            "of Rome lived on through the Latin language, Roman law, and the institutions of\n",
            "the Catholic Church. The memory of Roman grandeur continued to inspire political\n",
            "and cultural movements throughout European history, from the Holy Roman Empire\n",
            "to the Renaissance.\n",
            "\n",
            "So, the evolution of the Roman Empire is a complex and multifaceted tale,\n",
            "encompassing over a thousand years of history. It’s a story of rise, decline,\n",
            "and transformation, of brilliant achievements and devastating failures. It's a\n",
            "story that continues to fascinate and influence us today, reminding us of the\n",
            "enduring power of ideas, institutions, and the human capacity for both greatness\n",
            "and self-destruction. It's a cautionary tale about the fragility of even the\n",
            "most powerful empires and the importance of adaptability in the face of change.\n",
            "And hopefully, this long-winded description has given you a good starting point\n",
            "for further exploration!\n"
          ]
        }
      ],
      "source": [
        "#code is not necessary for colab.ai, but is useful in fomatting text chunks\n",
        "import sys\n",
        "from google.colab import ai\n",
        "\n",
        "\n",
        "class LineWrapper:\n",
        "    def __init__(self, max_length=80):\n",
        "        self.max_length = max_length\n",
        "        self.current_line_length = 0\n",
        "\n",
        "    def print(self, text_chunk):\n",
        "        i = 0\n",
        "        n = len(text_chunk)\n",
        "        while i < n:\n",
        "            start_index = i\n",
        "            while i < n and text_chunk[i] not in ' \\n': # Find end of word\n",
        "                i += 1\n",
        "            current_word = text_chunk[start_index:i]\n",
        "\n",
        "            delimiter = \"\"\n",
        "            if i < n: # If not end of chunk, we found a delimiter\n",
        "                delimiter = text_chunk[i]\n",
        "                i += 1 # Consume delimiter\n",
        "\n",
        "            if current_word:\n",
        "                needs_leading_space = (self.current_line_length > 0)\n",
        "\n",
        "                # Case 1: Word itself is too long for a line (must be broken)\n",
        "                if len(current_word) > self.max_length:\n",
        "                    if needs_leading_space: # Newline if current line has content\n",
        "                        sys.stdout.write('\\n')\n",
        "                        self.current_line_length = 0\n",
        "                    for char_val in current_word: # Break the long word\n",
        "                        if self.current_line_length >= self.max_length:\n",
        "                            sys.stdout.write('\\n')\n",
        "                            self.current_line_length = 0\n",
        "                        sys.stdout.write(char_val)\n",
        "                        self.current_line_length += 1\n",
        "                # Case 2: Word doesn't fit on current line (print on new line)\n",
        "                elif self.current_line_length + (1 if needs_leading_space else 0) + len(current_word) > self.max_length:\n",
        "                    sys.stdout.write('\\n')\n",
        "                    sys.stdout.write(current_word)\n",
        "                    self.current_line_length = len(current_word)\n",
        "                # Case 3: Word fits on current line\n",
        "                else:\n",
        "                    if needs_leading_space:\n",
        "                        # Define punctuation that should not have a leading space\n",
        "                        # when they form an entire \"word\" (token) following another word.\n",
        "                        no_leading_space_punctuation = {\n",
        "                            \",\", \".\", \";\", \":\", \"!\", \"?\",        # Standard sentence punctuation\n",
        "                            \")\", \"]\", \"}\",                     # Closing brackets\n",
        "                            \"'s\", \"'S\", \"'re\", \"'RE\", \"'ve\", \"'VE\", # Common contractions\n",
        "                            \"'m\", \"'M\", \"'ll\", \"'LL\", \"'d\", \"'D\",\n",
        "                            \"n't\", \"N'T\",\n",
        "                            \"...\", \"…\"                          # Ellipses\n",
        "                        }\n",
        "                        if current_word not in no_leading_space_punctuation:\n",
        "                            sys.stdout.write(' ')\n",
        "                            self.current_line_length += 1\n",
        "                    sys.stdout.write(current_word)\n",
        "                    self.current_line_length += len(current_word)\n",
        "\n",
        "            if delimiter == '\\n':\n",
        "                sys.stdout.write('\\n')\n",
        "                self.current_line_length = 0\n",
        "            elif delimiter == ' ':\n",
        "                # If line is full and a space delimiter arrives, it implies a wrap.\n",
        "                if self.current_line_length >= self.max_length:\n",
        "                    sys.stdout.write('\\n')\n",
        "                    self.current_line_length = 0\n",
        "\n",
        "        sys.stdout.flush()\n",
        "\n",
        "\n",
        "wrapper = LineWrapper()\n",
        "for chunk in ai.generate_text('Give me a long winded description about the evolution of the Roman Empire.', model_name='google/gemini-2.0-flash', stream=True):\n",
        "  wrapper.print(chunk)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "913b7d4c"
      },
      "source": [
        "# Task\n",
        "Generate text for multiple prompts using the `colab.ai` API to demonstrate sequential text generation capabilities, and clarify the current limitations of `colab.ai` regarding external API exposure."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "754367ca"
      },
      "source": [
        "## Clarify colab.ai Capabilities\n",
        "\n",
        "### Subtask:\n",
        "Explain the current capabilities of the `colab.ai` API, focusing on its use for text generation within the Colab environment and clarifying that direct external API exposure via tools like ngrok is not natively supported.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70091001"
      },
      "source": [
        "The `colab.ai` API is specifically designed to facilitate text generation tasks directly within the Google Colab environment. It provides a convenient way to access and utilize various large language models (LLMs) for tasks like content creation, summarization, and interactive AI assistance, all contained within your Colab notebook.\n",
        "\n",
        "**Important Note:** Currently, `colab.ai` does not support direct external API exposure. This means that you cannot use `colab.ai` to host models for external applications or services via tools like ngrok or similar tunneling services. Its functionality is strictly confined to the Colab runtime where it is invoked."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a133078e"
      },
      "source": [
        "The `colab.ai` API is specifically designed to facilitate text generation tasks directly within the Google Colab environment. It provides a convenient way to access and utilize various large language models (LLMs) for tasks like content creation, summarization, and interactive AI assistance, all contained within your Colab notebook.\n",
        "\n",
        "**Important Note:** Currently, `colab.ai` does not support direct external API exposure. This means that you cannot use `colab.ai` to host models for external applications or services via tools like ngrok or similar tunneling services. Its functionality is strictly confined to the Colab runtime where it is invoked."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "955e4a97"
      },
      "source": [
        "The `colab.ai` API is specifically designed to facilitate text generation tasks directly within the Google Colab environment. It provides a convenient way to access and utilize various large language models (LLMs) for tasks like content creation, summarization, and interactive AI assistance, all contained within your Colab notebook.\n",
        "\n",
        "**Important Note:** Currently, `colab.ai` does not support direct external API exposure. This means that you cannot use `colab.ai` to host models for external applications or services via tools like ngrok or similar tunneling services. Its functionality is strictly confined to the Colab runtime where it is invoked."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8a7dc11"
      },
      "source": [
        "## Prepare Multiple Prompts\n",
        "\n",
        "### Subtask:\n",
        "Define a list of several prompts to simulate 'batching' requests for text generation from a model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "588e95a6"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to define a list of prompts for text generation as per the instructions. This will involve creating a Python list named `prompts` and populating it with distinct text prompts.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6327d993",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c683859c-74ed-4a66-bfff-b7c1b2de7a70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created a list of 4 prompts:\n",
            "1. What is the capital of Canada?\n",
            "2. Write a short poem about a cat.\n",
            "3. Explain the concept of machine learning in simple terms.\n",
            "4. What are the benefits of eating healthy?\n"
          ]
        }
      ],
      "source": [
        "prompts = [\n",
        "    \"What is the capital of Canada?\",\n",
        "    \"Write a short poem about a cat.\",\n",
        "    \"Explain the concept of machine learning in simple terms.\",\n",
        "    \"What are the benefits of eating healthy?\"\n",
        "]\n",
        "\n",
        "print(f\"Created a list of {len(prompts)} prompts:\")\n",
        "for i, prompt in enumerate(prompts):\n",
        "    print(f\"{i+1}. {prompt}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da03cd80"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask of defining multiple prompts has been completed. The next step is to use these prompts to generate text sequentially, as indicated by the main task \"demonstrate sequential text generation capabilities.\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2936cbb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8a93f7b-f8d6-4e72-b295-00fd3f608647"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Generating responses for multiple prompts ---\n",
            "\n",
            "Prompt 1: What is the capital of Canada?\n",
            "Response 1: The capital of Canada is **Ottawa**.\n",
            "\n",
            "Prompt 2: Write a short poem about a cat.\n",
            "Response 2: A shadow soft, a silent grace,\n",
            "Pads through life at its own pace.\n",
            "A sleepy blink, a gentle purr,\n",
            "Beneath a coat of silken fur.\n",
            "Then sudden dash, a playful leap,\n",
            "Secrets that the night will keep.\n",
            "A furry friend, both wild and mild,\n",
            "A cherished, curious, whiskered child.\n",
            "\n",
            "Prompt 3: Explain the concept of machine learning in simple terms.\n",
            "Response 3: Imagine you want a computer to do something, but instead of telling it *exactly* how to do it step-by-step (like a normal computer program), you let it **learn how to do it itself** from examples, much like a human or a child learns.\n",
            "\n",
            "Here's the breakdown in simple terms:\n",
            "\n",
            "1.  **Learning from Experience:**\n",
            "    Think about teaching a child to recognize a cat. You don't give them a long list of rules like \"it has fur, four legs, whiskers, meows, a tail, is usually small...\"\n",
            "    Instead, you show them many pictures of cats and say \"That's a cat!\" You also show them pictures of dogs, birds, and cars, and say \"That's NOT a cat!\"\n",
            "\n",
            "2.  **Finding Patterns:**\n",
            "    After seeing enough examples, the child starts to **notice patterns** – \"Oh, things with pointy ears, whiskers, and that make a 'meow' sound are usually cats!\" They've built an internal \"model\" or understanding.\n",
            "\n",
            "3.  **Making Predictions/Decisions:**\n",
            "    Eventually, you can show the child a brand new cat they've never seen before, and they can correctly identify it because they learned the patterns.\n",
            "\n",
            "**How Machine Learning Works for Computers:**\n",
            "\n",
            "*   **Data (the Examples):** You feed a computer a huge amount of \"data\" (like all those cat pictures, or emails marked as spam, or historical stock prices).\n",
            "*   **Algorithms (the Learning Process):** The computer uses special programs called \"algorithms\" (which are like sophisticated mathematical recipes) to sift through this data. These algorithms are designed to **automatically find patterns, relationships, and rules** within the data.\n",
            "*   **Model (the Learned Knowledge):** The patterns and rules the computer discovers are stored in something called a \"model.\" This model is the computer's \"understanding\" of what it has learned.\n",
            "*   **Predictions/Decisions (Applying Knowledge):** Once the model is built, you can give the computer new, unseen data (like a new email or a new image) and it will use its learned model to make a prediction or a decision (e.g., \"This is spam,\" \"This is a cat,\" \"This stock will go up\").\n",
            "\n",
            "**Why is it powerful?**\n",
            "\n",
            "For many complex tasks (like recognizing faces, translating languages, recommending products, or even driving a car), it's nearly impossible for a human programmer to write down *every single rule* the computer needs to follow. Machine Learning lets the computer **discover those complex rules itself** by looking at vast amounts of data.\n",
            "\n",
            "**In short:**\n",
            "\n",
            "**Machine learning is about teaching computers to learn from data to make predictions or decisions, instead of being explicitly programmed for every single task.**\n",
            "\n",
            "Prompt 4: What are the benefits of eating healthy?\n",
            "Response 4: Eating healthy is one of the most impactful things you can do for your overall well-being. The benefits are far-reaching, affecting your physical, mental, and emotional health, both in the short and long term.\n",
            "\n",
            "Here are some of the key benefits of eating healthy:\n",
            "\n",
            "**1. Increased Energy Levels:**\n",
            "*   Nutrient-rich foods provide a steady supply of energy, preventing those midday slumps and helping you feel more vibrant and productive throughout the day.\n",
            "*   They stabilize blood sugar, avoiding the spikes and crashes associated with processed foods and sugary drinks.\n",
            "\n",
            "**2. Improved Mood and Mental Health:**\n",
            "*   Certain nutrients (like omega-3s, B vitamins, and complex carbohydrates) play a crucial role in brain function and neurotransmitter production, which can positively impact mood, reduce symptoms of anxiety and depression, and promote emotional stability.\n",
            "*   A healthy gut (supported by a good diet) is also strongly linked to brain health.\n",
            "\n",
            "**3. Stronger Immune System:**\n",
            "*   A balanced diet rich in vitamins (C, D, E), minerals (zinc, selenium), and antioxidants fortifies your body's defenses, making you less susceptible to infections, colds, and flu.\n",
            "\n",
            "**4. Weight Management and Prevention of Obesity:**\n",
            "*   Eating wholesome, unprocessed foods helps you feel full and satisfied, making it easier to maintain a healthy weight or lose excess weight.\n",
            "*   It reduces the intake of empty calories, unhealthy fats, and sugars that contribute to weight gain.\n",
            "\n",
            "**5. Reduced Risk of Chronic Diseases:**\n",
            "*   **Heart Disease:** Lowers blood pressure, cholesterol, and triglyceride levels, significantly reducing the risk of heart attacks and strokes.\n",
            "*   **Type 2 Diabetes:** Helps regulate blood sugar levels, preventing insulin resistance.\n",
            "*   **Certain Cancers:** Antioxidants and phytochemicals in fruits, vegetables, and whole grains can protect cells from damage.\n",
            "*   **Osteoporosis:** Adequate calcium and Vitamin D intake supports strong bones.\n",
            "\n",
            "**6. Better Digestive Health:**\n",
            "*   Fiber-rich foods (fruits, vegetables, whole grains, legumes) promote regular bowel movements, prevent constipation, and support a healthy gut microbiome, which is crucial for overall health.\n",
            "\n",
            "**7. Enhanced Cognitive Function:**\n",
            "*   Nutrients like omega-3 fatty acids, antioxidants, and B vitamins support brain health, improving focus, memory, and concentration, and potentially reducing the risk of cognitive decline like dementia.\n",
            "\n",
            "**8. Healthier Skin, Hair, and Nails:**\n",
            "*   A diet rich in vitamins, minerals, and healthy fats nourishes your skin from within, promoting a clearer complexion, faster healing, and a more youthful glow. It also strengthens hair and nails.\n",
            "\n",
            "**9. Better Sleep Quality:**\n",
            "*   Avoiding heavy, fatty, or sugary foods close to bedtime, and ensuring a balanced intake of nutrients, can contribute to more restful and restorative sleep.\n",
            "\n",
            "**10. Increased Longevity and Quality of Life:**\n",
            "*   By preventing diseases and supporting all bodily functions, healthy eating helps you live a longer, healthier life with more vitality, mobility, and independence in your later years.\n",
            "\n",
            "**11. Improved Physical Performance:**\n",
            "*   For athletes or anyone active, a healthy diet provides the necessary fuel for energy, muscle repair, and recovery, leading to better performance and reduced injury risk.\n",
            "\n",
            "In essence, eating healthy is an investment in yourself that pays dividends across every aspect of your life. It's not about restriction, but about nourishing your body and mind to thrive.\n",
            "\n",
            "--- All responses generated ---\n"
          ]
        }
      ],
      "source": [
        "from google.colab import ai\n",
        "\n",
        "print(\"--- Generating responses for multiple prompts ---\")\n",
        "responses = []\n",
        "for i, prompt in enumerate(prompts):\n",
        "    print(f\"\\nPrompt {i+1}: {prompt}\")\n",
        "    response = ai.generate_text(prompt)\n",
        "    responses.append(response)\n",
        "    print(f\"Response {i+1}: {response}\")\n",
        "\n",
        "print(\"\\n--- All responses generated ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1e5ef2e"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Summarize the demonstration of generating text for multiple prompts and reiterate the current limitations regarding external API exposure for `colab.ai` models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a843f46d"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "1.  **Summary of generating text for multiple prompts:** The process successfully demonstrated sequential text generation by defining a list of four distinct prompts (e.g., \"What is the capital of Canada?\", \"Write a short poem about a cat.\") and then iterating through them to generate a response for each using `colab.ai.generate_text()`. The generated responses were coherent and relevant to their respective prompts, showcasing the API's ability to handle diverse text generation requests.\n",
        "2.  **Current limitations regarding external API exposure for `colab.ai` models:** `colab.ai` does not currently support direct external API exposure. This means it cannot be used to host models for external applications or services via tunneling services like ngrok, as its functionality is strictly confined to the Google Colab runtime environment.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   The `colab.ai` API is designed exclusively for text generation tasks within the Google Colab environment, providing access to large language models for various content creation and AI assistance needs.\n",
        "*   **A significant limitation is that `colab.ai` does not support direct external API exposure, meaning it cannot be used with external services or tools like ngrok for hosting models.**\n",
        "*   The `colab.ai` API effectively generated coherent and relevant text responses for multiple diverse prompts sequentially, including factual questions, creative writing, and explanatory requests.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   Given the current limitations, `colab.ai` is best suited for in-notebook prototyping, experimentation, and educational purposes rather than production-level external application integration.\n",
        "*   Future enhancements could include exploring secure, controlled methods for limited external API access or publishing generated content, expanding the utility of `colab.ai` beyond the Colab runtime.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a953619d"
      },
      "source": [
        "# Task\n",
        "Instalar las bibliotecas Flask y pyngrok y crear una API Flask sencilla con al menos un endpoint que utilice `colab.ai` internamente para generar texto, para luego exponer esta API públicamente usando ngrok, probando el acceso externo y resumiendo las limitaciones de `colab.ai` respecto a la exposición directa de API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e7fef28"
      },
      "source": [
        "## Instalar dependencias\n",
        "\n",
        "### Subtask:\n",
        "Instalar las bibliotecas Flask y pyngrok necesarias en el entorno de Colab.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "o3i4m35Ggnfx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbd8173f"
      },
      "source": [
        "**Reasoning**:\n",
        "To install the required libraries Flask and pyngrok, I need to execute `pip install` commands in a code block.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ca14b88e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cb46f4e-7d11-4086-c5e6-3126cefd87e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Flask in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from Flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from Flask) (8.3.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from Flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from Flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Flask) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from Flask) (3.1.5)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.12/dist-packages (7.5.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install Flask\n",
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bada113e"
      },
      "source": [
        "## Crear API Flask Sencilla\n",
        "\n",
        "### Subtask:\n",
        "Escribir el código Python para definir una aplicación Flask básica con al menos un endpoint. Este endpoint puede, por ejemplo, devolver un mensaje simple o procesar una entrada.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eff63de"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to write Python code to define a basic Flask application with a root endpoint that returns a simple string message, as per the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0a0e11bd"
      },
      "outputs": [],
      "source": [
        "from flask import Flask\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return \"¡Hola desde Flask en Colab!\"\n",
        "\n",
        "# To run Flask in Colab, you'll typically use ngrok to expose it, but this basic setup\n",
        "# focuses on defining the application logic first. Actual running with ngrok will be in the next step.\n",
        "# For now, we just define the app."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eca3f11"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code block defined the Flask application but did not include the execution logic. As per the instructions, I need to add the `if __name__ == '__main__':` block to run the Flask app on port 5000, which is a necessary step before exposing it via ngrok.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4fab188",
        "outputId": "93c01fbc-040a-4cd0-8746-e94f9fa2d67f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Buscando y eliminando procesos ngrok zombies ---\n",
            "✅ No se encontraron procesos ngrok activos en el sistema.\n",
            "Esperando unos segundos para liberar puertos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2026-02-05T07:13:05+0000 lvl=warn msg=\"failed to start tunnel\" pg=/api/tunnels id=0039818262c634e1 err=\"failed to start tunnel: The endpoint 'https://unomitted-teodora-unennobling.ngrok-free.dev' is already online. Either\\n1. stop your existing endpoint first, or\\n2. start both endpoints with `--pooling-enabled` to load balance between them.\\r\\n\\r\\nERR_NGROK_334\\r\\n\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⚠️ ERROR AL INICIAR: ngrok client exception, API returned 502: {\"error_code\":103,\"status_code\":502,\"msg\":\"failed to start tunnel\",\"details\":{\"err\":\"failed to start tunnel: The endpoint 'https://unomitted-teodora-unennobling.ngrok-free.dev' is already online. Either\\n1. stop your existing endpoint first, or\\n2. start both endpoints with `--pooling-enabled` to load balance between them.\\r\\n\\r\\nERR_NGROK_334\\r\\n\"}}\n",
            "\n",
            "Si el error persiste, por favor reinicia el entorno (Runtime -> Restart session).\n"
          ]
        }
      ],
      "source": [
        "from flask import Flask, jsonify\n",
        "import flask\n",
        "from google.colab import ai\n",
        "from pyngrok import ngrok\n",
        "import os\n",
        "import time\n",
        "import subprocess\n",
        "import signal\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Definir el endpoint raíz\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return \"¡La API de Colab AI está activa! Usa /generate?prompt=... para probarla.\"\n",
        "\n",
        "# Definir el endpoint que usa colab.ai\n",
        "@app.route('/generate', methods=['GET', 'POST'])\n",
        "def generate():\n",
        "    req = flask.request\n",
        "    prompt = req.args.get('prompt') or (req.json.get('prompt') if req.is_json else None)\n",
        "\n",
        "    if not prompt:\n",
        "        return jsonify({'error': 'Por favor proporciona un parametro prompt'}), 400\n",
        "\n",
        "    try:\n",
        "        generated_text = ai.generate_text(prompt)\n",
        "        return jsonify({\n",
        "            'prompt': prompt,\n",
        "            'response': generated_text\n",
        "        })\n",
        "    except Exception as e:\n",
        "        return jsonify({'error': str(e)}), 500\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # 1. Configurar Token\n",
        "    # (Usamos el token que proporcionaste para asegurar que funcione directo)\n",
        "    auth_token = \"38C7qOpsgGgphXiJk02QkZLk6rD_3wcqGWSeRpqzjgdKHbDRo\"\n",
        "    ngrok.set_auth_token(auth_token)\n",
        "\n",
        "    # 2. LIMPIEZA NUCLEAR DE PROCESOS ANTERIORES\n",
        "    print(\"--- Buscando y eliminando procesos ngrok zombies ---\")\n",
        "    ngrok.kill()\n",
        "    try:\n",
        "        # Buscar PIDs de ngrok para matarlos definitivamente\n",
        "        result = subprocess.check_output([\"pgrep\", \"-f\", \"ngrok\"])\n",
        "        pids = result.decode().split()\n",
        "        for pid in pids:\n",
        "            try:\n",
        "                os.kill(int(pid), signal.SIGKILL)\n",
        "                print(f\"🔫 Proceso ngrok eliminado forzosamente: {pid}\")\n",
        "            except OSError:\n",
        "                pass\n",
        "    except subprocess.CalledProcessError:\n",
        "        print(\"✅ No se encontraron procesos ngrok activos en el sistema.\")\n",
        "\n",
        "    # Esperar a que el sistema operativo libere los puertos\n",
        "    print(\"Esperando unos segundos para liberar puertos...\")\n",
        "    time.sleep(3)\n",
        "\n",
        "    # 3. Iniciar Túnel\n",
        "    try:\n",
        "        public_url = ngrok.connect(5000).public_url\n",
        "        print(f\"\\n✅ API PÚBLICA DISPONIBLE EN: {public_url}\")\n",
        "        print(f\"   Prueba: {public_url}/generate?prompt=Hola\")\n",
        "\n",
        "        print(\"\\n--- RESUMEN DE LIMITACIONES DE COLAB.AI ---\")\n",
        "        print(\"1. colab.ai solo funciona dentro del runtime de Colab.\")\n",
        "        print(\"2. Requiere túneles (ngrok) para acceso externo.\")\n",
        "        print(\"3. La API muere si se cierra este notebook.\")\n",
        "        print(\"-------------------------------------------\\n\")\n",
        "\n",
        "        app.run(port=5000)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n⚠️ ERROR AL INICIAR: {e}\")\n",
        "        print(\"Si el error persiste, por favor reinicia el entorno (Runtime -> Restart session).\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oIV1x9sMbEWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OpcZwKhA-j6p"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}